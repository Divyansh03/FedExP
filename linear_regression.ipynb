{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "By7bcM2ArJ6v"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "from matplotlib.ticker import LinearLocator\n",
        "import csv\n",
        "\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_client_data(n,d,alpha,beta):\n",
        "\n",
        "  dimension = d\n",
        "  NUM_CLASS = 1\n",
        "  NUM_USER = n\n",
        "\n",
        "  # samples_per_user = np.random.lognormal(4, 1, (NUM_USER)).astype(int)\n",
        "\n",
        "  samples_per_user = [30 for i in range(NUM_USER)]\n",
        "\n",
        "  # print(samples_per_user)\n",
        "  num_samples = np.sum(samples_per_user)\n",
        "\n",
        "  X_split = [[] for _ in range(NUM_USER)]\n",
        "  y_split = [[] for _ in range(NUM_USER)]\n",
        "\n",
        "\n",
        "  #### define some prior ####\n",
        "  mean_W = np.random.normal(0, alpha, NUM_USER)\n",
        "  mean_b = mean_W\n",
        "  B = np.random.normal(0, beta, NUM_USER)\n",
        "  mean_x = np.zeros((NUM_USER, dimension))\n",
        "\n",
        "  diagonal = np.zeros(dimension)\n",
        "\n",
        "  cov_x = np.eye(d)\n",
        "\n",
        "  for i in range(NUM_USER):\n",
        "      mean_x[i] = np.random.normal(B[i], 1, dimension)\n",
        "\n",
        "\n",
        "  for i in range(NUM_USER):\n",
        "\n",
        "      W = np.random.normal(mean_W[i], 1, (dimension, NUM_CLASS))\n",
        "\n",
        "      xx = np.random.multivariate_normal(mean_x[i], cov_x, samples_per_user[i])\n",
        "\n",
        "      yy = np.dot(xx,W)\n",
        "\n",
        "      X_split[i] = xx\n",
        "      y_split[i] = yy.flatten()\n",
        "\n",
        "      # print(\"{}-th users has {} examples\".format(i, len(y_split[i])))\n",
        "\n",
        "\n",
        "  return X_split, y_split"
      ],
      "metadata": {
        "id": "14YQO7im0AJp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A_client, b_client = get_client_data(20,1000,0.1,0.1)"
      ],
      "metadata": {
        "id": "i0tDnO5n0S8a"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from re import S\n",
        "\n",
        "\n",
        "d= 1000\n",
        "s= 30\n",
        "n= 20\n",
        "\n",
        "\n",
        "A= np.zeros((s*n,d))\n",
        "b = np.zeros((s*n))\n",
        "\n",
        "w_sol = np.zeros((n,d))\n",
        "\n",
        "\n",
        "J = []\n",
        "e = []\n",
        "c = []\n",
        "V = []\n",
        "\n",
        "J_sum = np.zeros((d,d))\n",
        "e_sum = np.zeros(d)\n",
        "\n",
        "extra_dim = 0\n",
        "A_mat = []\n",
        "\n",
        "for i in range(n):\n",
        "\n",
        "    A_i = A_client[i]\n",
        "    b_i = b_client[i][0:s]\n",
        "\n",
        "    for j in range(s):\n",
        "      A_i[j] = A_i[j]/np.linalg.norm(A_i[j])\n",
        "\n",
        "    b_i = b_i/np.linalg.norm(b_i)\n",
        "\n",
        "    A[i*s:(i+1)*s] = A_i\n",
        "    b[i*s:(i+1)*s] = b_i\n",
        "\n",
        "    A_mat.append(A_i)\n",
        "\n",
        "    u, si, vh = np.linalg.svd(A_i)\n",
        "    v_t = vh[0:s]\n",
        "\n",
        "\n",
        "    \n",
        "    V_t = v_t.T.dot(v_t)\n",
        "\n",
        "\n",
        "    V.append(V_t)\n",
        "\n",
        "    H_i = A_i.dot(A_i.T)\n",
        "    J_i = A_i.T.dot(A_i)\n",
        "\n",
        "    J_sum += J_i\n",
        "\n",
        "    e_i = A_i.T.dot(b_i)\n",
        "\n",
        "    e_sum += e_i\n",
        "\n",
        "    c_i = np.zeros((d,))\n",
        "\n",
        "    J.append(J_i)\n",
        "    e.append(e_i)\n",
        "    c.append(c_i)\n",
        "\n",
        "\n",
        "    w_sol_i = A_i.T.dot(np.linalg.pinv(H_i).dot(b_i))\n",
        "\n",
        "    w_sol[i] = w_sol_i\n",
        "\n",
        "J_sum = J_sum\n",
        "e_sum = e_sum\n",
        "\n",
        "\n",
        "V_sum = np.zeros((d,d))\n",
        "w_sum = np.zeros((d,))\n",
        "\n",
        "\n",
        "for i in range(n):\n",
        "  V_sum += V[i]\n",
        "  w_sum += w_sol[i]\n",
        "\n",
        "V_sum = V_sum/n\n",
        "w_sum = w_sum/n\n",
        "\n"
      ],
      "metadata": {
        "id": "_2hfDOkrrRQv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_local_gd(i,tau,w,eta):\n",
        "\n",
        "  w_0 = np.copy(w)\n",
        "\n",
        "  for t in range(tau):\n",
        "\n",
        "    grad = J[i].dot(w_0)-e[i]\n",
        "    w_0 = w_0 - eta*grad\n",
        "\n",
        "\n",
        "  return (w-w_0)"
      ],
      "metadata": {
        "id": "mYh6ZWlC364C"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scaffold(i,tau,w,eta,c,c_avg):\n",
        "\n",
        "  w_0 = np.copy(w)\n",
        "\n",
        "\n",
        "  for t in range(tau):\n",
        "\n",
        "    grad = (J[i].dot(w_0)-e[i])\n",
        "    grad = grad - c[i] + c_avg\n",
        "    w_0 = w_0 - eta*grad\n",
        "    \n",
        "  c[i] = c[i] - c_avg + (w-w_0)/(eta*tau)\n",
        "\n",
        "  return (w-w_0)"
      ],
      "metadata": {
        "id": "VnACkcJ83-Ch"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fedprox(i,tau,w,eta,mu):\n",
        "\n",
        "  w_0 = np.copy(w)\n",
        "\n",
        "\n",
        "  for t in range(tau):\n",
        "\n",
        "    grad = (J[i].dot(w_0)-e[i]) + mu*(w_0-w)\n",
        "    w_0 = w_0 - eta*grad\n",
        "\n",
        "  return (w-w_0)"
      ],
      "metadata": {
        "id": "bJjARoOG51IL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = 'scaffold'\n",
        "s2 = 'fedavg'\n",
        "s3 = 'fedexp'\n",
        "s4 = 'fedadagrad'\n",
        "s5 = 'fedprox'\n"
      ],
      "metadata": {
        "id": "y9iq9ZT68Q-4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_alg = {}\n",
        "w_dist_alg = {}\n",
        "traj_alg_x = {}\n",
        "traj_alg_y = {}\n",
        "w_final = {}\n",
        "grad_div_alg = {}"
      ],
      "metadata": {
        "id": "k1pjPKyA4KIx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T= 200\n",
        "\n",
        "tau = 20\n",
        "\n",
        "w_0 = np.zeros((d))\n",
        "\n",
        "\n",
        "dict_results = {}\n",
        "\n",
        "filename = \"results_\"+\"linear_regression\"\n",
        "filename_txt = filename + \".txt\"\n"
      ],
      "metadata": {
        "id": "etN-Qf6n4Ehr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####Hyperparameter optimization code\n",
        "\n",
        "\n",
        "algs = [s1,s2,s3,s4,s5]\n",
        "\n",
        "eta_g_alg = {s1:10,s2:10,s3:10, s4:0.1, s5:10}\n",
        "eta_l_alg = {s1:0.1,s2:0.1,s3:0.1, s4:0.1, s5:0.1}\n",
        "mu = 0.01\n",
        "\n",
        "\n",
        "\n",
        "for alg in algs:\n",
        "  hyp_train_loss_algo = []\n",
        "  dict_results[alg] = {}\n",
        "  eta_g = eta_g_alg[alg]\n",
        "  eta_l = eta_l_alg[alg]\n",
        "   \n",
        "  c = np.zeros((n,d))\n",
        "  w = w_0.copy()\n",
        "  w_prev = w_0.copy()\n",
        "  loss = []\n",
        "  eta_g_var = []\n",
        "  delta = np.zeros((d,))\n",
        "  \n",
        "\n",
        "  for t in range(T):\n",
        "\n",
        "    c_avg = np.zeros((d,))\n",
        "    grad_avg = np.zeros((d,))\n",
        "   \n",
        "\n",
        "    for i in range(n):\n",
        "        c_avg += c[i]\n",
        "\n",
        "    c_avg = c_avg/n\n",
        "\n",
        "    grad_norm_avg = 0\n",
        "\n",
        "    if(alg== s3):\n",
        "      w_loss = (w+w_prev)/2\n",
        "    else: w_loss = w\n",
        "\n",
        "    if(t%5==0):\n",
        "        F = (np.linalg.norm(A.dot(w_loss)-b)**2)/n\n",
        "        loss.append(F)\n",
        "        print (alg, t, F)\n",
        "    \n",
        "    for i in range(n):\n",
        "      if(alg==s2 or alg==s3 or alg==s4):\n",
        "        grad = do_local_gd(i,tau,w,eta_l)\n",
        "      elif(alg==s1):\n",
        "        grad = scaffold(i,tau,w,eta_l,c,c_avg)\n",
        "      elif(alg==s5):\n",
        "        grad = fedprox(i,tau,w,eta_l,mu)\n",
        "        \n",
        "\n",
        "      grad_avg += grad\n",
        "      grad_norm_avg += np.linalg.norm(grad)**2\n",
        "\n",
        "\n",
        "    grad_avg = grad_avg/n\n",
        "    grad_norm_avg = grad_norm_avg/n\n",
        "    grad_avg_norm = np.linalg.norm(grad_avg)**2\n",
        "\n",
        "\n",
        "    w_prev = w.copy()\n",
        "    scale = eta_g\n",
        "\n",
        "    if(alg == s1 or alg==s2 or alg==s5):\n",
        "\n",
        "      w = w-eta_g*grad_avg\n",
        "\n",
        "    if(alg==s4):\n",
        "      delta = delta + grad_avg**2\n",
        "      grad_avg = grad_avg/np.sqrt(delta)\n",
        "\n",
        "      w = w-eta_g*grad_avg\n",
        "\n",
        "    if (alg ==s3):\n",
        "\n",
        "      scale = 0.5*grad_norm_avg/(grad_avg_norm)\n",
        "\n",
        "      w = w - (scale)*grad_avg\n",
        "\n",
        "    eta_g_var.append(scale)\n",
        "    \n",
        "    w_prev = w.copy()\n",
        "\n",
        "\n",
        "  print (loss)\n",
        "  dict_results[alg][alg+\"_training_loss\"] = loss\n",
        "  dict_results[alg][alg+\"_global_learning_rate\"] = eta_g_var\n",
        "\n",
        "  with open(filename_txt, 'w') as f:    \n",
        "        for i in dict_results.keys():\n",
        "          for key, value in dict_results[i].items():\n",
        "            f.write(key+\" \")\n",
        "            f.write(str(value))\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "C8G1MjRcNE-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = []\n",
        "\n",
        "for t in range(T):\n",
        "    if(t==0 or (t)%5==0):\n",
        "        x.append(t)\n",
        "        \n",
        "\n",
        "  \n",
        "for alg in dict_results:\n",
        "  plt.plot(x,dict_results[alg][alg+\"_training_loss\"], label=alg)\n",
        "  plt.yscale('log')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E2x-wd0li2eV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}